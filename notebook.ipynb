{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import pack\n",
    "from features import Features,feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optimization\n",
    "feat=Features(**pack)\n",
    "data=feat.execute()\n",
    "container=feature_selection(data)\n",
    "trainx=container.trainx\n",
    "trainy=container.trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from xgboost import XGBClassifier, DMatrix\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, DeltaYStopper\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from functools import partial\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_perf(optimizer, X, y, title=\"model\", callbacks=None):\n",
    "    start = time()\n",
    "    if callbacks is not None:\n",
    "        optimizer.fit(X, y, callback=callbacks)\n",
    "    else:\n",
    "        optimizer.fit(X, y)\n",
    "\n",
    "    d = pd.DataFrame(optimizer.cv_results_)\n",
    "    best_score = optimizer.best_score_\n",
    "    best_score_std = d.iloc[optimizer.best_index_].std_test_score\n",
    "    best_params = optimizer.best_params_\n",
    "\n",
    "    print((title + \" took %.2f seconds,  candidates checked: %d, best CV score: %.3f \"+ u\"\\u00B1\"+\" %.3f\") % (time() - start,len(optimizer.cv_results_['params']),best_score,best_score_std))\n",
    "    print('Best parameters:')\n",
    "    pprint.pprint(best_params)\n",
    "    print()\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= XGBClassifier(random_state=0, booster='gbtree', tree_method='hist', verbosity = 0)  #gpu_hist for gpu train\n",
    "scoring = make_scorer(partial(accuracy_score), greater_is_better=False)\n",
    "skf = StratifiedKFold(n_splits=7,shuffle=True,random_state=0)\n",
    "cv_strategy = list(skf.split(trainx,trainy))\n",
    "\n",
    "\n",
    "search_spaces = {'learning_rate': Real(0.01, 1.0, 'uniform'),\n",
    "                 'max_depth': Integer(2, 12),\n",
    "                 'subsample': Real(0.1, 1.0, 'uniform'),\n",
    "                 # subsample ratio of columns by tree\n",
    "                 'colsample_bytree': Real(0.1, 1.0, 'uniform'),\n",
    "                 # L2 regularization\n",
    "                 'reg_lambda': Real(1e-9, 100., 'uniform'),\n",
    "                 'reg_alpha': Real(1e-9, 100., 'uniform'),  # L1 regularization\n",
    "                 'n_estimators': Integer(50, 5000)\n",
    "                 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BayesSearchCV(estimator=model,\n",
    "                    search_spaces=search_spaces,\n",
    "                    scoring=scoring,\n",
    "                    cv=cv_strategy,\n",
    "                    n_iter=120,                                       # max number of trials\n",
    "                    # number of hyperparameter sets evaluated at the same time\n",
    "                    n_points=1,\n",
    "                    n_jobs=1,                                  \n",
    "                    # if not iid it optimizes on the cv score\n",
    "                    iid=False,\n",
    "                    return_train_score=False,\n",
    "                    refit=False,\n",
    "                    # optmizer parameters: we use Gaussian Process (GP)\n",
    "                    optimizer_kwargs={'base_estimator': 'GP'},\n",
    "                    random_state=0)                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/home2/Documents/PROJECTS/premier_league_match_predictions/notebook.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/home2/Documents/PROJECTS/premier_league_match_predictions/notebook.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m opt\u001b[39m.\u001b[39;49mfit(trainx,trainy)\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/skopt/searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs_ \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs)\n\u001b[0;32m--> 466\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, groups\u001b[39m=\u001b[39;49mgroups, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    468\u001b[0m \u001b[39m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/skopt/searchcv.py:512\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39mwhile\u001b[39;00m n_iter \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    509\u001b[0m     \u001b[39m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     n_points_adjusted \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 512\u001b[0m     optim_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step(\n\u001b[1;32m    513\u001b[0m         search_space, optimizer,\n\u001b[1;32m    514\u001b[0m         evaluate_candidates, n_points\u001b[39m=\u001b[39;49mn_points_adjusted\n\u001b[1;32m    515\u001b[0m     )\n\u001b[1;32m    516\u001b[0m     n_iter \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m n_points\n\u001b[1;32m    518\u001b[0m     \u001b[39mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/skopt/searchcv.py:408\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39m# make lists into dictionaries\u001b[39;00m\n\u001b[1;32m    406\u001b[0m params_dict \u001b[39m=\u001b[39m [point_asdict(search_space, p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m params]\n\u001b[0;32m--> 408\u001b[0m all_results \u001b[39m=\u001b[39m evaluate_candidates(params_dict)\n\u001b[1;32m    409\u001b[0m \u001b[39m# Feed the point and objective value back into optimizer\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39m# Optimizer minimizes objective, hence provide negative score\u001b[39;00m\n\u001b[1;32m    411\u001b[0m local_results \u001b[39m=\u001b[39m all_results[\u001b[39m\"\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(params):]\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m         clone(base_estimator),\n\u001b[1;32m    841\u001b[0m         X,\n\u001b[1;32m    842\u001b[0m         y,\n\u001b[1;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    849\u001b[0m     )\n\u001b[1;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    852\u001b[0m     )\n\u001b[1;32m    853\u001b[0m )\n\u001b[1;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    682\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/xgboost/core.py:506\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    505\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 506\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/xgboost/sklearn.py:1250\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1230\u001b[0m model, feval, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(xgb_model, eval_metric, params)\n\u001b[1;32m   1231\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1232\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1233\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     label_transform\u001b[39m=\u001b[39mlabel_transform,\n\u001b[1;32m   1248\u001b[0m )\n\u001b[0;32m-> 1250\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1251\u001b[0m     params,\n\u001b[1;32m   1252\u001b[0m     train_dmatrix,\n\u001b[1;32m   1253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1254\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1255\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1256\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1257\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1258\u001b[0m     feval\u001b[39m=\u001b[39;49mfeval,\n\u001b[1;32m   1259\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1260\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1261\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1262\u001b[0m )\n\u001b[1;32m   1264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/xgboost/training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, evals\u001b[39m=\u001b[39m(), obj\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, feval\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    116\u001b[0m           maximize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, early_stopping_rounds\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, evals_result\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m           verbose_eval\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, xgb_model\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, callbacks\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m     \u001b[39m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[39m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39m    Booster : a trained booster model\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     bst \u001b[39m=\u001b[39m _train_internal(params, dtrain,\n\u001b[1;32m    189\u001b[0m                           num_boost_round\u001b[39m=\u001b[39;49mnum_boost_round,\n\u001b[1;32m    190\u001b[0m                           evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m    191\u001b[0m                           obj\u001b[39m=\u001b[39;49mobj, feval\u001b[39m=\u001b[39;49mfeval,\n\u001b[1;32m    192\u001b[0m                           xgb_model\u001b[39m=\u001b[39;49mxgb_model, callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    193\u001b[0m                           verbose_eval\u001b[39m=\u001b[39;49mverbose_eval,\n\u001b[1;32m    194\u001b[0m                           evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m    195\u001b[0m                           maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    196\u001b[0m                           early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds)\n\u001b[1;32m    197\u001b[0m     \u001b[39mreturn\u001b[39;00m bst\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/xgboost/training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m callbacks\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     80\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m callbacks\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     83\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/xgboost/core.py:1680\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1679\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1680\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1681\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1682\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1683\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt.fit(trainx,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/home2/Documents/PROJECTS/premier_league_match_predictions/notebook.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/home2/Documents/PROJECTS/premier_league_match_predictions/notebook.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# We impose a time limit (7 hours)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/home2/Documents/PROJECTS/premier_league_match_predictions/notebook.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m time_limit_control \u001b[39m=\u001b[39m DeadlineStopper(total_time\u001b[39m=\u001b[39m\u001b[39m60\u001b[39m\u001b[39m*\u001b[39m\u001b[39m60\u001b[39m\u001b[39m*\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/home2/Documents/PROJECTS/premier_league_match_predictions/notebook.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m best_params \u001b[39m=\u001b[39m report_perf(opt, trainx,trainy, \u001b[39m'\u001b[39;49m\u001b[39mXGBoost_classif\u001b[39;49m\u001b[39m'\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[overdone_control, time_limit_control])\n",
      "\u001b[1;32m/Users/home2/Documents/PROJECTS/premier_league_match_predictions/notebook.ipynb Cell 9\u001b[0m in \u001b[0;36mreport_perf\u001b[0;34m(optimizer, X, y, title, callbacks)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/home2/Documents/PROJECTS/premier_league_match_predictions/notebook.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/home2/Documents/PROJECTS/premier_league_match_predictions/notebook.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m callbacks \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/home2/Documents/PROJECTS/premier_league_match_predictions/notebook.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mfit(X, y, callback\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/home2/Documents/PROJECTS/premier_league_match_predictions/notebook.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/home2/Documents/PROJECTS/premier_league_match_predictions/notebook.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mfit(X, y)\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/skopt/searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs_ \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs)\n\u001b[0;32m--> 466\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, groups\u001b[39m=\u001b[39;49mgroups, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    468\u001b[0m \u001b[39m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/skopt/searchcv.py:512\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39mwhile\u001b[39;00m n_iter \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    509\u001b[0m     \u001b[39m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     n_points_adjusted \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 512\u001b[0m     optim_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step(\n\u001b[1;32m    513\u001b[0m         search_space, optimizer,\n\u001b[1;32m    514\u001b[0m         evaluate_candidates, n_points\u001b[39m=\u001b[39;49mn_points_adjusted\n\u001b[1;32m    515\u001b[0m     )\n\u001b[1;32m    516\u001b[0m     n_iter \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m n_points\n\u001b[1;32m    518\u001b[0m     \u001b[39mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/skopt/searchcv.py:408\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39m# make lists into dictionaries\u001b[39;00m\n\u001b[1;32m    406\u001b[0m params_dict \u001b[39m=\u001b[39m [point_asdict(search_space, p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m params]\n\u001b[0;32m--> 408\u001b[0m all_results \u001b[39m=\u001b[39m evaluate_candidates(params_dict)\n\u001b[1;32m    409\u001b[0m \u001b[39m# Feed the point and objective value back into optimizer\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39m# Optimizer minimizes objective, hence provide negative score\u001b[39;00m\n\u001b[1;32m    411\u001b[0m local_results \u001b[39m=\u001b[39m all_results[\u001b[39m\"\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(params):]\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m         clone(base_estimator),\n\u001b[1;32m    841\u001b[0m         X,\n\u001b[1;32m    842\u001b[0m         y,\n\u001b[1;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    849\u001b[0m     )\n\u001b[1;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    852\u001b[0m     )\n\u001b[1;32m    853\u001b[0m )\n\u001b[1;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    682\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/xgboost/core.py:506\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    505\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 506\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/xgboost/sklearn.py:1250\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1230\u001b[0m model, feval, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(xgb_model, eval_metric, params)\n\u001b[1;32m   1231\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1232\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1233\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     label_transform\u001b[39m=\u001b[39mlabel_transform,\n\u001b[1;32m   1248\u001b[0m )\n\u001b[0;32m-> 1250\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1251\u001b[0m     params,\n\u001b[1;32m   1252\u001b[0m     train_dmatrix,\n\u001b[1;32m   1253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1254\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1255\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1256\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1257\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1258\u001b[0m     feval\u001b[39m=\u001b[39;49mfeval,\n\u001b[1;32m   1259\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1260\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1261\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1262\u001b[0m )\n\u001b[1;32m   1264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/xgboost/training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, evals\u001b[39m=\u001b[39m(), obj\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, feval\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    116\u001b[0m           maximize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, early_stopping_rounds\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, evals_result\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m           verbose_eval\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, xgb_model\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, callbacks\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m     \u001b[39m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[39m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39m    Booster : a trained booster model\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     bst \u001b[39m=\u001b[39m _train_internal(params, dtrain,\n\u001b[1;32m    189\u001b[0m                           num_boost_round\u001b[39m=\u001b[39;49mnum_boost_round,\n\u001b[1;32m    190\u001b[0m                           evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m    191\u001b[0m                           obj\u001b[39m=\u001b[39;49mobj, feval\u001b[39m=\u001b[39;49mfeval,\n\u001b[1;32m    192\u001b[0m                           xgb_model\u001b[39m=\u001b[39;49mxgb_model, callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    193\u001b[0m                           verbose_eval\u001b[39m=\u001b[39;49mverbose_eval,\n\u001b[1;32m    194\u001b[0m                           evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m    195\u001b[0m                           maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    196\u001b[0m                           early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds)\n\u001b[1;32m    197\u001b[0m     \u001b[39mreturn\u001b[39;00m bst\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/xgboost/training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m callbacks\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     80\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m callbacks\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     83\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/xgboost/core.py:1680\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1679\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1680\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1681\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1682\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1683\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "overdone_control = DeltaYStopper(delta=0.0001)\n",
    "time_limit_control = DeadlineStopper(total_time=60*60*4)\n",
    "best_params = report_perf(opt, trainx,trainy, 'XGBoost_classif',callbacks=[overdone_control, time_limit_control])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(random_state=0, booster='gbtree', tree_method='hist', verbosity = 0 ,**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 RMSE: 1.00000\n",
      "Fold 1 RMSE: 1.00000\n",
      "Fold 2 RMSE: 1.00000\n",
      "Fold 3 RMSE: 1.00000\n",
      "Fold 4 RMSE: 1.00000\n",
      "Fold 5 RMSE: 1.00000\n",
      "Fold 6 RMSE: 1.00000\n",
      "Fold 7 RMSE: 1.00000\n",
      "Fold 8 RMSE: 1.00000\n",
      "Fold 9 RMSE: 1.00000\n",
      "repeated CV RMSE: 1.00000 (std=0.00000)\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "skf = StratifiedKFold(n_splits=folds,shuffle=True,random_state=0)\n",
    "rmse = list()\n",
    "\n",
    "for k, (train_idx, val_idx) in enumerate(skf.split(trainx,trainy)):\n",
    "    model.fit(trainx.iloc[train_idx].values, trainy.iloc[train_idx].values)\n",
    "    val_preds = model.predict(trainx.iloc[val_idx].values)\n",
    "    val_rmse = accuracy_score(y_true=trainy.iloc[val_idx].values, y_pred=val_preds)\n",
    "    print(f\"Fold {k} RMSE: {val_rmse:0.5f}\")\n",
    "    rmse.append(val_rmse)\n",
    "print(f\"repeated CV RMSE: {np.mean(rmse):0.5f} (std={np.std(rmse):0.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89cfa167d153742a51790af676de7b3c0d8354fe0bd3b02aa53d1c3f327566f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
