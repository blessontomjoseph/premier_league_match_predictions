{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of features failed: Traceback (most recent call last):\n",
      "  File \"/Users/home2/.conda/envs/py38/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/home2/.conda/envs/py38/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/home2/.conda/envs/py38/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 839, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 976, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 906, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/home2/Documents/PROJECTS/premier_league_match_predictions/features.py\", line 87\n",
      "    data.season=\n",
      "               ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# \"chr=conceded-home-rolling\"\n",
    "# \"car=conceded-away-rolling\"\n",
    "# \"hr=home-rolling\"\n",
    "# \"ar=away-rolling\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import pack\n",
    "from features import Features, feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optimization\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = Features(**pack)\n",
    "data = feat.execute()\n",
    "container = feature_selection(data)\n",
    "trainx = container.trainx\n",
    "trainy = container.trainy\n",
    "\n",
    "def encoder(data,feat):\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    oe=OrdinalEncoder()\n",
    "    data[feat]=oe.fit_transform(data[feat])\n",
    "    return data\n",
    "\n",
    "trainx=encoder(trainx,['hometeam','awayteam','referee'])\n",
    "# best_params = optimization.optimizer(\n",
    "    # trainx.iloc[:10], trainy.iloc[:10], 'XGBoost_classif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>referee</th>\n",
       "      <th>hometeam</th>\n",
       "      <th>awayteam</th>\n",
       "      <th>ftg_hr</th>\n",
       "      <th>htg_hr</th>\n",
       "      <th>s_hr</th>\n",
       "      <th>st_hr</th>\n",
       "      <th>c_hr</th>\n",
       "      <th>f_hr</th>\n",
       "      <th>...</th>\n",
       "      <th>htg_car</th>\n",
       "      <th>s_car</th>\n",
       "      <th>st_car</th>\n",
       "      <th>c_car</th>\n",
       "      <th>f_car</th>\n",
       "      <th>y_car</th>\n",
       "      <th>r_car</th>\n",
       "      <th>p_car</th>\n",
       "      <th>hp_car</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01</td>\n",
       "      <td>122.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01</td>\n",
       "      <td>54.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>10.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>13.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01</td>\n",
       "      <td>91.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-01</td>\n",
       "      <td>108.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000-01</td>\n",
       "      <td>135.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000-01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000-01</td>\n",
       "      <td>136.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>14.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    season  referee  hometeam  awayteam    ftg_hr    htg_hr       s_hr  \\\n",
       "0  2000-01    122.0      12.0      25.0  0.666667  0.333333  11.000000   \n",
       "1  2000-01     54.0      13.0      41.0  1.000000  0.166667   7.833333   \n",
       "2  2000-01     15.0      14.0      27.0  2.500000  1.166667  13.000000   \n",
       "3  2000-01     10.0      16.0      34.0  1.500000  0.666667   8.666667   \n",
       "4  2000-01     38.0      22.0      17.0  0.833333  0.000000   8.000000   \n",
       "5  2000-01     91.0      23.0       1.0  1.500000  0.500000  11.666667   \n",
       "6  2000-01    108.0      24.0       7.0  1.166667  0.166667  12.500000   \n",
       "7  2000-01    135.0      36.0       0.0  0.666667  0.500000   8.333333   \n",
       "8  2000-01      9.0      38.0      21.0  0.333333  0.000000   6.166667   \n",
       "9  2000-01    136.0      26.0      28.0  1.666667  0.500000  17.666667   \n",
       "\n",
       "      st_hr      c_hr       f_hr  ...  htg_car  s_car  st_car  c_car  f_car  \\\n",
       "0  3.666667  4.166667  10.000000  ...      0.4    9.3     5.2    4.8   10.4   \n",
       "1  3.166667  3.166667  10.166667  ...      1.1   13.4     6.3    5.7   12.8   \n",
       "2  5.500000  4.166667  10.500000  ...      0.7    9.7     3.2    5.3   16.2   \n",
       "3  4.166667  5.000000  10.166667  ...      0.4    7.9     4.5    5.1   14.1   \n",
       "4  3.333333  4.333333  11.666667  ...      0.6   11.8     4.7    6.4   12.9   \n",
       "5  4.166667  6.166667  11.166667  ...      0.2   11.9     4.8    6.9    9.8   \n",
       "6  4.666667  6.500000   9.000000  ...      1.2   12.2     6.4    6.8   11.6   \n",
       "7  3.333333  2.166667  14.333333  ...      0.3   11.2     4.2    4.4   12.2   \n",
       "8  1.333333  2.666667   8.500000  ...      1.0   13.5     5.8    5.0   10.5   \n",
       "9  5.666667  7.666667   8.166667  ...      1.2   14.6     6.4    6.2   12.7   \n",
       "\n",
       "   y_car  r_car  p_car  hp_car  day  \n",
       "0    1.2    0.2    1.1     1.3    6  \n",
       "1    1.7    0.0    2.0     2.1    6  \n",
       "2    2.9    0.1    0.5     1.0    6  \n",
       "3    1.6    0.1    0.4     0.6    6  \n",
       "4    1.7    0.0    1.3     0.8    6  \n",
       "5    1.8    0.0    1.2     0.9    6  \n",
       "6    1.6    0.0    2.4     1.9    6  \n",
       "7    2.1    0.0    1.1     1.1    6  \n",
       "8    1.3    0.0    2.2     1.6    6  \n",
       "9    1.3    0.0    1.8     2.2    7  \n",
       "\n",
       "[10 rows x 45 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx.iloc[:10]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# best_params = OrderedDict([('colsample_bytree', 1.0),\n",
    "#                            ('learning_rate', 0.14006304478391782),\n",
    "#                            ('max_depth', 10),\n",
    "#                            ('n_estimators', 50),\n",
    "#                            ('subsample', 1.0)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = XGBClassifier(random_state=0, booster='gbtree', tree_method='hist',objective='multi:softprob' ,\n",
    "                       eval_metric=accuracy_score, verbosity=0, **best_params)\n",
    "\n",
    "\n",
    "def train(trainx, trainy):\n",
    "    folds = 10\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=0)\n",
    "    train_acc, val_acc = [], []\n",
    "    \n",
    "    \n",
    "    for k, (train_idx, val_idx) in enumerate(skf.split(trainx, trainy)):\n",
    "        model.fit(trainx.iloc[train_idx].values, trainy.iloc[train_idx].values)\n",
    "        train_preds = model.predict(trainx.iloc[train_idx].values)\n",
    "        val_preds = model.predict(trainx.iloc[val_idx].values)\n",
    "        \n",
    "        acc_t = accuracy_score(\n",
    "            y_true=trainy.iloc[train_idx].values, y_pred=train_preds)\n",
    "        acc_v = accuracy_score(\n",
    "            y_true=trainy.iloc[val_idx].values, y_pred=val_preds)\n",
    "        train_acc.append(acc_t)\n",
    "        val_acc.append(acc_v)\n",
    "    return np.mean(train_acc), np.mean(val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import features\n",
    "# best = features.auto_best_features(trainx, trainy, n_features=30)\n",
    "trainx,valx,trainy,valy=train_test_split(trainx,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx.reset_index(inplace=True,drop=True)\n",
    "trainy.reset_index(inplace=True,drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1120  304  472]\n",
      " [ 693 2523 1103]\n",
      " [   0    1    0]]\n",
      "0.6747762385564946\n",
      "0.586068211068211\n",
      "0.8083123674112912\n"
     ]
    }
   ],
   "source": [
    "model.fit(trainx,trainy)\n",
    "t_preds=model.predict(trainx)\n",
    "v_preds=model.predict(valx)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(t_preds,trainy))\n",
    "print(f1_score(t_preds,trainy,average='weighted'))\n",
    "print(recall_score(t_preds,trainy,average='weighted'))\n",
    "print(precision_score(t_preds,trainy,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[267 107 128]\n",
      " [123 527 184]\n",
      " [ 67  82  69]]\n",
      "0.5771379548782624\n",
      "0.5553410553410554\n",
      "0.6091527018753423\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(v_preds,valy))\n",
    "print(f1_score(v_preds,valy,average='weighted'))\n",
    "print(recall_score(v_preds,valy,average='weighted'))\n",
    "print(precision_score(v_preds,valy,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi = features.mutual_information(best, trainy)\n",
    "# features.plotmi(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_acc,val_acc=train(best, trainy)\n",
    "# train_acc,val_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(trainy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9823862979360414, 0.5702755779327867)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(trainx,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the optimal parameters and by training and validating multiple times -the training and validation can be daone in loop or in single sert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Loader:\n",
    "    def __init__(self,x,y):\n",
    "        self.trainx=x.values\n",
    "        self.trainy=y.values\n",
    "    def __len__(self):\n",
    "        return len(self.trainx)\n",
    "    def __getitem__(self,idx):\n",
    "        return {'x':self.trainx[idx],'y':self.trainy[idx]}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "t_x,v_x,t_y,v_y=train_test_split(trainx,trainy,test_size=0.2)\n",
    "trainloader=DataLoader(Loader(t_x,t_y),batch_size=64)\n",
    "val_loader=DataLoader(Loader(v_x,v_y),batch_size=8)\n",
    "best_params = OrderedDict([('colsample_bytree', 1.0),\n",
    "                           ('learning_rate', 0.14006304478391782),\n",
    "                           ('max_depth', 10),\n",
    "                           ('n_estimators', 50),\n",
    "                           ('subsample', 1.0)])\n",
    "model = XGBClassifier(random_state=0, booster='gbtree', tree_method='hist', eval_metric='mlogloss', objective='multi:softprob' ,verbosity=0, **best_params)\n",
    "model.fit(t_x,t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89cfa167d153742a51790af676de7b3c0d8354fe0bd3b02aa53d1c3f327566f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
